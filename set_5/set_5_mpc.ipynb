{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.832: Problem Set #5 -  Part 2 of 2\n",
    "\n",
    "Due on Friday, May 3, 2019 at 23:59.  See course website for submission details. Use Drake release tag `drake-20190423`, i.e. use this notebook via `./docker_run_notebook.sh drake-20190423 .`, or whichever script you need for your platform.\n",
    "\n",
    "May the 4th be with you!\n",
    "\n",
    "## Dynamic control for manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, you developed a tool for analyzing whether a given grasp of an object is likely to be stable or not. In this section, we'll develop a tool for controlling the robot and object after that grasp has been achieved. Where the previous section used a simplified model that largely ignored the details of the robot, we'll embrace the object and robot dynamics here to write a simple but powerful controller to manipulate the object in the robot's hand!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The controller\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "We're going to write a controller for a fully-actuated, fixed-base robot hand that has grabbed an unactuated rigid object (the \"manipuland\"). Note that taken together, the robot+object can be considered an underactuated system. The whole system is pictured below, and constructed in the *BuildHand* function in *planar_hand.py*.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"hand_diagram.png\" width=\"350\"/>\n",
    "</p>\n",
    "\n",
    "To be specific, for every finger, you have direct torque control of each joint (including the base joint) of the finger. (That is, everything rendered in red.) There are no joint limits, and all motion takes place in the XY plane (so there is no gravity). You'll have a perfect estimate of the robot and manipuland state.\n",
    "\n",
    "Our controller will assume that the robot has exactly achieved the desired grasp (that is, a fingertip is in contact with the object at each of a set of positions on the object), and that it'll maintain that grasp for the rest of time. It also assumes no other contacts exist. A natural extension of this controller would be to include an estimator of the contact state and contact locations -- and to react accordingly by planning to achieve contact, and planning regrasps when necessary -- but let's start simple!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "The core objectives are to:\n",
    "\n",
    "1) **Control the hand and manipuland to follow a desired trajectory through space.**\n",
    "\n",
    "2) **Regulate the contact normal forces with the manipuland.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "An ideal approach for this problem would be to perform a trajectory optimization far into the future at every time step, starting from the current state, and optimize your control actions to cause the object to move as desired and achieve the desired contact forces. That's usually intractable, though -- but what if you only simulated a *single* step forward in time? We'll construct a quadratic (convex) optimization that searches over feasible inputs, accelerations, and contact forces to achieve our above objectives. This is exactly the kind of control we use to, for example, [drive Atlas](http://groups.csail.mit.edu/robotics-center/public_papers/Kuindersma13.pdf) -- it works very well!\n",
    "\n",
    "### Instantaneous dynamics\n",
    "\n",
    "In this case, if you assume your instantaneous dynamics will be valid until your next control tick, your dynamics become linear! You can see that from the manipulator equations. In the case with contact, our robot has dynamics\n",
    "\n",
    "$$\n",
    "M(q) \\ddot{q} + C(q, \\dot{q}) v = Bu + \\Phi(q)^T \\lambda\n",
    "$$\n",
    "\n",
    "following [C.3.1 in the textbook](http://underactuated.csail.mit.edu/underactuated.html?chapter=multibody). For a vector of contact forces (in world frame) $\\lambda$, they affect the system dynamics by operating through the contact Jacobian $\\Phi$, which is itself a function of the robot state. Instantaneously, $q$ and $v$ are known and constant, so $\\ddot{q}$, $\\lambda$, and $u$ enter linearly.\n",
    "\n",
    "*($\\Phi$ is described in some detail in the textbook, but the core idea is that it maps contact forces in generalized (world) coordinates into the joint coordinates of the robot. In our case of forces occuring from point contacts, then you can think about $\\Phi$ as describing how movement of the contact point is reflected in the joint coordinates of the robot. Check out the code for how we calculate it in this case!)*\n",
    "\n",
    "### Modeling feasible contacts\n",
    "\n",
    "The second piece of this puzzle is that not all contact forces are feasible: assuming a fixed set of non-sliding contacts means the contact forces must only push on the manipuland, and they must also obey coulomb friction. These are exactly the friction cone constraints from the previous section -- though because our contact forces will be expressed in world frame, we'll describe the (instantaneous) friction cone in world frame as well.\n",
    "\n",
    "Take $\\lambda$ to be a stack of world-frame contact forces $\\left[\\lambda_1, ..., \\lambda_n\\right]$ for individual planar contact forces $\\lambda_i = \\left[\\lambda_{i,x}, \\lambda_{i,y}\\right]$. At a given instant, $\\lambda_i$ must live inside a cone positively spanned by vectors $c_{i, 0}$ and $c_{i, 2}$: \n",
    "\n",
    "$$\\lambda_i = c_{i, 1} * \\beta_{i, 1} + c_{i, 2} * \\beta_{i, 2} \\ \\ \\ \\beta_{i, 0}, \\beta_{i, 1} \\geq 0$$\n",
    "\n",
    "where the vectors $c_{i, j}$ are calculated in world frame using the contact normal and tangent vectors at the $i^{th}$ grasp point, which are transformed depending on the pose and shape of the manipuland.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"friction_cone_world_frame.png\" width=\"400\"/>\n",
    "</p>\n",
    "\n",
    "### Objective function\n",
    "\n",
    "The above constraints allow you to represent the dynamics of this robot in its given contact configuration linearly. So if you construct a quadratic objective, you'll stay within the efficiently-solvable world of quadratic programs!\n",
    "\n",
    "As noted in class, there's a lot of room for freedom in designing the objective here. Since you have direct access to $\\ddot{q}$, $\\lambda$, and the other decision variables, achieving goals (1) and (2) from the problem statement should be fairly direct.\n",
    "\n",
    "*(Where do the supplied hand postures come from? Good question! Included in this set is an example of solving an inverse kinematics problem (as a nonlinear optimization) to find a posture for the robot that achieves the desired contact locations given the current object location while remaining close to a reasonable \"nominal\" posture. It works in real time for this small system, but might be hard to scale. What we're writing here is more of a controller than a planner -- often roboticists will generate a trajectory of desired postures ahead of time using a non-real-time trajectory optimization, and then use a controller like this one to stabilize it in real time.)*\n",
    "\n",
    "### Full formulation\n",
    "\n",
    "This leads us to a full formulation for single-step dynamics-aware control given this contact situation.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\min_{\\ddot{q}, \\lambda, u, \\beta} Q(q, \\dot{q}, \\ddot{q}, \\lambda, u) \\\\\n",
    "s.t. \\ & M \\ddot{q} + C = Bu +\\Phi^T \\lambda \\\\\n",
    "& \\lambda_i = c_{i, 0} \\beta_{i, 0} + c_{i, 1} \\beta_{i, 1} \\ \\ \\ \\forall i \\\\\n",
    "& \\beta_{i, j} \\geq 0 \\ \\ \\ \\forall i, j\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $q$ and $\\dot{q}$ are supplied and constant, and $M$, $C$, $\\Phi$, and the friction cone basis vectors $c_{i, j}$ are evaluated (and so also constant) at that configuration, for a quadratic objective $Q$ that you'll design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOUR MISSION\n",
    "\n",
    "The file `planar_hand.py` includes everything you need to set up and simulate this system, and this notebook provides examples below for simulating the complete system. It assumes that you've completed the grasp evaluation methods from the other notebook, so go do those first if you haven't.\n",
    "\n",
    "**Implement the above controller in the `ComputeControlInput` method of the `HandController` class.** Feel free to peruse the rest of the controller to understand what it's doing -- at a high level, the major methods are described below.\n",
    "\n",
    "To clarify -- you ONLY need to implement the remaining portion of `ComputeControlInput` -- nothing else!  Also the first half of this function has been implemented for you.\n",
    "\n",
    "If you're feeling lost, the precise order in which we recommend you proceed is:\n",
    "\n",
    "1) Start out ignoring contacts, and write a Q that only worries about controlling $q^{hand}$ to $q^{hand}_{des}$. The whole optimization should look something like\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\min_{\\ddot{q}, u} K_p ||q^{hand}_{des} - q^{hand}||^2 + K_d ||\\dot{q}^{hand}_{des} - \\dot{q}^{hand}||^2 \\\\\n",
    "s.t. \\ & M \\ddot{q} + C = Bu \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "where $K_p$ and $K_d$ are PD control gains for regulating the arm posture. This should control the hand to achieve the contact points (while accounting for the dynamics of the arm), and as a consequence move the object around (though not very well).\n",
    "\n",
    "2) Then worry about writing the complete optimization written above (that also searches over contact forces that obey friction cone constraints), with additional terms in the objective to regulate the object position. (Feel free to experiment with other things, too -- like encouraging contact force to be large, weighting different joints of the hand differently, etc. But these aren't strictly necessary to complete the set.)\n",
    "\n",
    "### Specs\n",
    "\n",
    "The tests will spawn the system with between 2 and 4 fingers and several simple manipuland trajectories. The exact `manipuland_trajectory_callback` functions it'll use are copied below, for your reference. For each of these, it will check:\n",
    "\n",
    "1) That the final posture of the manipuland was within 0.25 of the desired goal pose in all dimensions. \n",
    "\n",
    "2) That the average contact force (across all contacts that happened) during the last 1 second of a 10 second simulation was always above 0.1. (i.e., a reasonable grip was maintained).\n",
    "\n",
    "### Guide the the rest of the code\n",
    "\n",
    "1) `PlanGraspPoints`, which extracts the geometry of the manipuland and randomly samples sets of grasp points on its surface, picking the best one by using your metrics to check if it is force closure and ranking the force closure grasps by their volume. (It also double-checks that the grasps are reachable by the robot by doing a ComputeTargetPosture call, and uses a neat LP to decide which finger will grab which grasp point.)\n",
    "\n",
    "2) `GetDesiredObjectPosition`, which dispatches to a `manipuland_trajectory_callback` to provide manipuland pose goals given a time. These are the manipuland pose goals the controller will try to track.\n",
    "\n",
    "3) `ComputeTargetPosture`, which computes a posture for the hand that puts the fingertips where they should be to hold the object at a specified pose, while keeping the hand close to a specified nominal posture. It assumes `PlanGraspPoints` has already been called so it can use the grasp points that were chosen. It uses Drake's inverse kinematic helper class (which helps set up a nonlinear optimization to optimize over robot postures) -- a very powerful class that might be useful in your final projects! We use it nonstop on all of our robots -- for example, to [get Atlas into the car](https://www.youtube.com/watch?v=m1rv4d_zUCY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import planar_hand\n",
    "\n",
    "# You can change this number to change\n",
    "# the number of fingers added to the\n",
    "# hand. More than 5 gets hard.\n",
    "num_fingers = 2\n",
    "# There are 3 joints per finger, so\n",
    "# the number of positions for the whole hand is...\n",
    "num_hand_q = num_fingers * 3\n",
    "\n",
    "# Feel free to tweak, but this pose works\n",
    "# reasoanbly well given this hand size.\n",
    "initial_manipuland_pose = np.array([1.5, 0., 0.])\n",
    "\n",
    "# Change this callback to change the nominal\n",
    "# trajectory for the manipuland through space.\n",
    "# The default example moves the object from \n",
    "# [1, 0, 0] to [1, 0.5, 0.5].\n",
    "# Make sure the initial pose matches your initial\n",
    "# manipuland pose, defined above.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "def manipuland_trajectory_callback_custom(t):\n",
    "    ''' Must return a 3x1 numpy array of floats, indicating\n",
    "        the desired manipuland pose (x y theta) at time t.'''\n",
    "    return np.array([1.5 + 0.5 * math.sin(t/2.), 0.5 * math.sin(t/3.), 0.0])\n",
    "\n",
    "# The callbacks used for testing, for your convenience.\n",
    "def test_manipuland_trajectory_callback_A(t):\n",
    "    return np.array([1.5, 0.5 * sigmoid(t - 2.5), 0.5 * sigmoid(t - 2.5)])\n",
    "def test_manipuland_trajectory_callback_B(t):\n",
    "    return np.array([1.5, -0.5 * sigmoid(t - 2.5), 0.5 * sigmoid(t - 2.5)])\n",
    "def test_manipuland_trajectory_callback_C(t):\n",
    "    return np.array([1.5 - 0.5 * sigmoid(t - 2.5), 0.5, 0.0])\n",
    "\n",
    "# Run the simulation. Parameters not described above\n",
    "# are:\n",
    "#   - The duration of simulation (in seconds)\n",
    "#   - # of random grasp point sets to use when searching\n",
    "#     for a grasp of the object.\n",
    "#   - The period of the controller update (your QP is called at this rate)\n",
    "#   - The coefficient of friction assumed by the controller. Does not\n",
    "#     affect the simulator (whose friction is fixed to 0.9). A conservative\n",
    "#     value of 0.5 works pretty well.\n",
    "#   - The manipuland sdf. Options included in this set are:\n",
    "#       \"models/manipuland_ball.sdf\"\n",
    "#       \"models/manipuland_ball_large.sdf\"\n",
    "#       \"models/manipuland_box.sdf\"\n",
    "#       \"models/manipuland_irregular_blob.sdf\"\n",
    "#       \"models/manipuland_triangle.sdf\"\n",
    "hand, plant, controller, state_log, contact_log = \\\n",
    "    planar_hand.SimulateHand(\n",
    "        num_fingers=num_fingers,\n",
    "        manipuland_sdf=\"models/manipuland_box.sdf\",\n",
    "        mu=0.5,\n",
    "        initial_manipuland_pose=initial_manipuland_pose,\n",
    "        manipuland_trajectory_callback = test_manipuland_trajectory_callback_C,\n",
    "        duration=10,\n",
    "        n_grasp_search_iters=100,\n",
    "        control_period = 0.0333)\n",
    "\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the simulation as a video\n",
    "import matplotlib.pyplot as plt\n",
    "from underactuated import PlanarRigidBodyVisualizer\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "fig.set_size_inches(6, 6)\n",
    "# This custom Tview creates a top-down view.\n",
    "# (It functions as a projection matrix -- 3D poses are\n",
    "# multiplied by it to produce their position in the view\n",
    "# window.)\n",
    "viz = PlanarRigidBodyVisualizer(hand, xlim=[-2, 4], ylim=[-3, 3],\n",
    "                   Tview=np.array([[1., 0., 0., 0.],\n",
    "                                   [0., 1., 0., 0.],\n",
    "                                   [0., 0., 0., 1.]]),\n",
    "                   #fig=fig,\n",
    "                   ax=ax)\n",
    "# This extra visualizer overlays the contact forces.\n",
    "hand_viz = planar_hand.PlanarHandExtrasVisualizer(controller,\n",
    "                                                  plant,\n",
    "                                                  viz,\n",
    "                                                  fig=fig,\n",
    "                                                  ax=ax,\n",
    "                                                  show_forces=True)\n",
    "ani = hand_viz.animate(state_log, contact_log, 0.0333, repeat=True)\n",
    "plt.close(fig)\n",
    "# This needs to be the last line for the video to display\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell plots object pose tracking performance across time\n",
    "# The object pose comes after the hand pose in the state\n",
    "# vector, so extract it here.\n",
    "object_pose_history = state_log.data()[num_hand_q:(num_hand_q+3), :]\n",
    "ts = state_log.sample_times()\n",
    "object_target_pose_history = np.vstack([\n",
    "        controller.GetDesiredObjectPosition(t)\n",
    "        for t in ts\n",
    "    ]).T\n",
    "\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(ts, object_pose_history[0, :], label=\"X actual pose\")\n",
    "plt.plot(ts, object_target_pose_history[0, :], label=\"X target pose\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(ts, object_pose_history[1, :], label=\"Y actual pose\")\n",
    "plt.plot(ts, object_target_pose_history[1, :], label=\"Y target pose\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(ts, object_pose_history[2, :], label=\"Theta actual pose\")\n",
    "plt.plot(ts, object_target_pose_history[2, :], label=\"Theta target pose\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel(\"t(seconds)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot contact force tracking across time\n",
    "# contact_log.data is a list (for every time point)\n",
    "# of lists (for every contact at that time point)\n",
    "# of tuples (id_1, id_2, r, f):\n",
    "#  id_1 being the object ID of the first object in the contact pair\n",
    "#  id_2 being the object ID of the first object in the contact pair\n",
    "#  r being the contact location, in world frame\n",
    "#  f being the contact force, in world frame\n",
    "ts = contact_log.sample_times()\n",
    "contact_results = contact_log.data()\n",
    "average_cf_over_time = np.zeros(len(ts))\n",
    "for i, cr in enumerate(contact_results):\n",
    "    if len(cr) > 0:\n",
    "        total_cf = 0.0\n",
    "        for id_1, id_2, r, f in cr:\n",
    "            total_cf += np.linalg.norm(f)\n",
    "        total_cf /= len(cr)\n",
    "        average_cf_over_time[i] = total_cf\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.plot(ts, average_cf_over_time)\n",
    "plt.title(\"Average contact force over time\")\n",
    "plt.xlabel(\"t(seconds)\")\n",
    "plt.ylabel(\"Average contact force over time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Run the tests\n",
    "os.popen(\"python test_set_5.py test_results.json\")\n",
    "\n",
    "# Print the results json for review\n",
    "import test_set_5\n",
    "print test_set_5.pretty_format_json_results(\"test_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
